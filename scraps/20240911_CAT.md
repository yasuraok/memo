# 用語集と翻訳メモリを使う

## 1. 目的
- 翻訳業者に翻訳を依頼する際に、一文単位でリストを作らされる場合がある
  - 日本語文を文単位にばらす & (レビューの場合) 英文を日本語に合わせてばらす
  - 翻訳結果を取り込む ← 難しい？
- 日本語を更新した後に英語が更新されていない状態を検出する
  - 本当に訳が変わるもの
  - 訳には無関係なもの … コンソールメッセージなど ← これが実は難しい？

### 1.1. 基本方針
- Computer-Assisted Translation tool (CATツール) の「翻訳メモリ」の考え方にIFやワークフローになるべく近づける → <a href="tm">翻訳メモリ</a>
- 試験問題管理システムの本線にはなるべく侵食しないワークフローにする
  翻訳メモリは試験アイテム本体とは別テーブルに格納する

## 2. ユースケース

### 2.1. 日本語の問題を作成したあと、新規に翻訳をする
1. GPTで仮翻訳する際に、翻訳と同時に結果を文ごとに分割する
2. 結果を文ごとに翻訳メモリに格納する。日本語側の複数文がまとめて1つの英文になった場合、まとめた状態で格納する。
3. (この翻訳メモリを元に日問題文から置換で英問題を作り、exam_itemにストアする)
4. (必要に応じて翻訳業者に翻訳してもらい、結果を取り込む (3と同じ方法が使えるはず))

### 2.2. 一度翻訳したものを更新する
1. (日本語を更新する)
2. 翻訳メモリに既存の翻訳があるか検索する
   1. 当初と同じルールで (原則句点ごとに) 文を分割する
   2. それぞれの文に対して翻訳メモリを検索する。完全一致しない場合に、**直後3文までjoinして検索する**。
3. 完全一致しなかった文を抽出し、…
   1. 翻訳メモリから部分一致を探してマニュアルで翻訳する
   2. (部分一致しなかった場合)、LLM or 手 or 翻訳業者なりで翻訳する → <a href="#fulltext_search">全文検索</a>
4. 結果を格納する

## 3. 技術メモ
### 3.1. 翻訳メモリ <a id="tm"></a>
https://ja.wikipedia.org/wiki/%E7%BF%BB%E8%A8%B3%E3%83%A1%E3%83%A2%E3%83%AA

### 3.2. 全文検索 > Embedding + ベクトル検索 <a id="fulltext_search"></a>
LLMのRAGにベクトルサーチを使いたい場合、RAGで引かれる文章セットの1つ1つの文章量はどれくらいが適切ですか？
試しに一文一文をベクトルDBのレコードに入れた場合、何となく類似文章が検索できなかった印象でした。
翻訳の日英ペアの文を1レコードとした翻訳メモリを構築したい場合、Embedding + ベクトル検索よりも適したアプローチがありますか？
例えばApache Luceneのようなツールの方がこの用途には近いでしょうか？
RAG（Retrieval-Augmented Generation）にベクトルサーチを使用する場合、各文章セットの文章量に対する適切なサイズは特定のユースケースやデータセットに依存しますが、一般的なガイドラインを提供することは可能です。
単一の文をベクトルDBのレコードにすることも可能ですが、個々の文が短すぎてコンテキストが不足する可能性があります。それにより、類似性の判断が難しくなることがあります。
https://www.ogis-ri.co.jp/otc/hiroba/technical/similar-document-search/part1.html
